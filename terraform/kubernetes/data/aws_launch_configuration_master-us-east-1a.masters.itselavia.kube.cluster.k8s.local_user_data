#!/bin/bash
# Copyright 2016 The Kubernetes Authors All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

set -o errexit
set -o nounset
set -o pipefail

NODEUP_URL=https://github.com/kubernetes/kops/releases/download/1.14.1/linux-amd64-nodeup,https://kubeupv2.s3.amazonaws.com/kops/1.14.1/linux/amd64/nodeup
NODEUP_HASH=2fc5a1223fb50d86f996b3a90c31f322185c03ad

export AWS_REGION=us-east-1




function ensure-install-dir() {
  INSTALL_DIR="/var/cache/kubernetes-install"
  # On ContainerOS, we install to /var/lib/toolbox install (because of noexec)
  if [[ -d /var/lib/toolbox ]]; then
    INSTALL_DIR="/var/lib/toolbox/kubernetes-install"
  fi
  mkdir -p ${INSTALL_DIR}
  cd ${INSTALL_DIR}
}

# Retry a download until we get it. args: name, sha, url1, url2...
download-or-bust() {
  local -r file="$1"
  local -r hash="$2"
  shift 2

  urls=( $* )
  while true; do
    for url in "${urls[@]}"; do
      if [[ -e "${file}" ]]; then
        echo "== File exists for ${url} =="

      # CoreOS runs this script in a container without which (but has curl)
      # Note also that busybox wget doesn't support wget --version, but busybox doesn't normally have curl
      # So we default to wget unless we see curl
      elif [[ $(curl --version) ]]; then
        if ! curl -f --ipv4 -Lo "${file}" --connect-timeout 20 --retry 6 --retry-delay 10 "${url}"; then
          echo "== Failed to curl ${url}. Retrying. =="
          continue
        fi
      else
        if ! wget --inet4-only -O "${file}" --connect-timeout=20 --tries=6 --wait=10 "${url}"; then
          echo "== Failed to wget ${url}. Retrying. =="
          continue
        fi
      fi

      if [[ -n "${hash}" ]] && ! validate-hash "${file}" "${hash}"; then
        echo "== Hash validation of ${url} failed. Retrying. =="
        rm -f "${file}"
      else
        if [[ -n "${hash}" ]]; then
          echo "== Downloaded ${url} (SHA1 = ${hash}) =="
        else
          echo "== Downloaded ${url} =="
        fi
        return
      fi
    done

    echo "All downloads failed; sleeping before retrying"
    sleep 60
  done
}

validate-hash() {
  local -r file="$1"
  local -r expected="$2"
  local actual

  actual=$(sha1sum ${file} | awk '{ print $1 }') || true
  if [[ "${actual}" != "${expected}" ]]; then
    echo "== ${file} corrupted, sha1 ${actual} doesn't match expected ${expected} =="
    return 1
  fi
}

function split-commas() {
  echo $1 | tr "," "\n"
}

function try-download-release() {
  # TODO(zmerlynn): Now we REALLY have no excuse not to do the reboot
  # optimization.

  local -r nodeup_urls=( $(split-commas "${NODEUP_URL}") )
  if [[ -n "${NODEUP_HASH:-}" ]]; then
    local -r nodeup_hash="${NODEUP_HASH}"
  else
  # TODO: Remove?
    echo "Downloading sha1 (not found in env)"
    download-or-bust nodeup.sha1 "" "${nodeup_urls[@]/%/.sha1}"
    local -r nodeup_hash=$(cat nodeup.sha1)
  fi

  echo "Downloading nodeup (${nodeup_urls[@]})"
  download-or-bust nodeup "${nodeup_hash}" "${nodeup_urls[@]}"

  chmod +x nodeup
}

function download-release() {
  # In case of failure checking integrity of release, retry.
  until try-download-release; do
    sleep 15
    echo "Couldn't download release. Retrying..."
  done

  echo "Running nodeup"
  # We can't run in the foreground because of https://github.com/docker/docker/issues/23793
  ( cd ${INSTALL_DIR}; ./nodeup --install-systemd-unit --conf=${INSTALL_DIR}/kube_env.yaml --v=8  )
}

####################################################################################

/bin/systemd-machine-id-setup || echo "failed to set up ensure machine-id configured"

echo "== nodeup node config starting =="
ensure-install-dir

cat > cluster_spec.yaml << '__EOF_CLUSTER_SPEC'
cloudConfig: null
docker:
  ipMasq: false
  ipTables: false
  logDriver: json-file
  logLevel: warn
  logOpt:
  - max-size=10m
  - max-file=5
  storage: overlay2,overlay,aufs
  version: 18.06.3
encryptionConfig: null
etcdClusters:
  events:
    cpuRequest: 100m
    memoryRequest: 100Mi
    version: 3.3.10
  main:
    cpuRequest: 200m
    memoryRequest: 100Mi
    version: 3.3.10
kubeAPIServer:
  allowPrivileged: true
  anonymousAuth: false
  apiServerCount: 1
  authorizationMode: RBAC
  bindAddress: 0.0.0.0
  cloudProvider: aws
  enableAdmissionPlugins:
  - NamespaceLifecycle
  - LimitRanger
  - ServiceAccount
  - PersistentVolumeLabel
  - DefaultStorageClass
  - DefaultTolerationSeconds
  - MutatingAdmissionWebhook
  - ValidatingAdmissionWebhook
  - NodeRestriction
  - ResourceQuota
  etcdServers:
  - http://127.0.0.1:4001
  etcdServersOverrides:
  - /events#http://127.0.0.1:4002
  image: k8s.gcr.io/kube-apiserver:v1.14.8
  insecureBindAddress: 127.0.0.1
  insecurePort: 8080
  kubeletPreferredAddressTypes:
  - InternalIP
  - Hostname
  - ExternalIP
  logLevel: 2
  requestheaderAllowedNames:
  - aggregator
  requestheaderExtraHeaderPrefixes:
  - X-Remote-Extra-
  requestheaderGroupHeaders:
  - X-Remote-Group
  requestheaderUsernameHeaders:
  - X-Remote-User
  securePort: 443
  serviceClusterIPRange: 172.20.0.0/19
  storageBackend: etcd3
kubeControllerManager:
  allocateNodeCIDRs: true
  attachDetachReconcileSyncPeriod: 1m0s
  cloudProvider: aws
  clusterCIDR: 172.20.128.0/17
  clusterName: itselavia.kube.cluster.k8s.local
  configureCloudRoutes: false
  image: k8s.gcr.io/kube-controller-manager:v1.14.8
  leaderElection:
    leaderElect: true
  logLevel: 2
  useServiceAccountCredentials: true
kubeProxy:
  cpuRequest: 100m
  hostnameOverride: '@aws'
  image: k8s.gcr.io/kube-proxy:v1.14.8
  logLevel: 2
kubeScheduler:
  image: k8s.gcr.io/kube-scheduler:v1.14.8
  leaderElection:
    leaderElect: true
  logLevel: 2
kubelet:
  anonymousAuth: false
  cgroupRoot: /
  cloudProvider: aws
  clusterDNS: 172.20.0.10
  clusterDomain: cluster.local
  enableDebuggingHandlers: true
  evictionHard: memory.available<100Mi,nodefs.available<10%,nodefs.inodesFree<5%,imagefs.available<10%,imagefs.inodesFree<5%
  featureGates:
    ExperimentalCriticalPodAnnotation: "true"
  hostnameOverride: '@aws'
  kubeconfigPath: /var/lib/kubelet/kubeconfig
  logLevel: 2
  networkPluginName: cni
  nonMasqueradeCIDR: 172.20.0.0/16
  podInfraContainerImage: k8s.gcr.io/pause-amd64:3.0
  podManifestPath: /etc/kubernetes/manifests
masterKubelet:
  anonymousAuth: false
  cgroupRoot: /
  cloudProvider: aws
  clusterDNS: 172.20.0.10
  clusterDomain: cluster.local
  enableDebuggingHandlers: true
  evictionHard: memory.available<100Mi,nodefs.available<10%,nodefs.inodesFree<5%,imagefs.available<10%,imagefs.inodesFree<5%
  featureGates:
    ExperimentalCriticalPodAnnotation: "true"
  hostnameOverride: '@aws'
  kubeconfigPath: /var/lib/kubelet/kubeconfig
  logLevel: 2
  networkPluginName: cni
  nonMasqueradeCIDR: 172.20.0.0/16
  podInfraContainerImage: k8s.gcr.io/pause-amd64:3.0
  podManifestPath: /etc/kubernetes/manifests
  registerSchedulable: false

__EOF_CLUSTER_SPEC

cat > ig_spec.yaml << '__EOF_IG_SPEC'
kubelet: null
nodeLabels:
  kops.k8s.io/instancegroup: master-us-east-1a
taints: null

__EOF_IG_SPEC

cat > kube_env.yaml << '__EOF_KUBE_ENV'
Assets:
- e964b489c434d3d2ea3cbaa424cb2c99fff7e301@https://storage.googleapis.com/kubernetes-release/release/v1.14.8/bin/linux/amd64/kubelet
- 192c0ec1cf9dc5e9eb8b86d2ce2129a9336a7ac2@https://storage.googleapis.com/kubernetes-release/release/v1.14.8/bin/linux/amd64/kubectl
- 52e9d2de8a5f927307d9397308735658ee44ab8d@https://storage.googleapis.com/kubernetes-release/network-plugins/cni-plugins-amd64-v0.7.5.tgz
- fbd28401ce71a75b7a7856504feb20afc6b234af@https://github.com/kubernetes/kops/releases/download/1.14.1/linux-amd64-utils.tar.gz,https://kubeupv2.s3.amazonaws.com/kops/1.14.1/linux/amd64/utils.tar.gz
ClusterName: itselavia.kube.cluster.k8s.local
ConfigBase: s3://itselavia-kops-state-store/itselavia.kube.cluster.k8s.local
InstanceGroupName: master-us-east-1a
Tags:
- _automatic_upgrades
- _aws
channels:
- s3://itselavia-kops-state-store/itselavia.kube.cluster.k8s.local/addons/bootstrap-channel.yaml
etcdManifests:
- s3://itselavia-kops-state-store/itselavia.kube.cluster.k8s.local/manifests/etcd/main.yaml
- s3://itselavia-kops-state-store/itselavia.kube.cluster.k8s.local/manifests/etcd/events.yaml
protokubeImage:
  hash: 78954cba06ec92b8f87e1ecbc35fbc1579c84837
  name: protokube:1.14.1
  sources:
  - https://github.com/kubernetes/kops/releases/download/1.14.1/images-protokube.tar.gz
  - https://kubeupv2.s3.amazonaws.com/kops/1.14.1/images/protokube.tar.gz

__EOF_KUBE_ENV

download-release
echo "== nodeup node config done =="
